## Introduction
EN:
This repository modifies the inference code of the Tooncrafter project to reduce GPU VRAM usage. You do not need to make any changes to model weights and other related files, and you can directly apply all the steps for deploying the original repository to this one.

Generated quality may experience a slight decrease.

CHS:
æœ¬ä»“åº“å¯¹Tooncrafteré¡¹ç›®çš„æ¨ç†ä»£ç è¿›è¡Œä¿®æ”¹ä»¥è¾¾åˆ°å‡å°‘æ˜¾å­˜å ç”¨çš„ç›®çš„ã€‚æ‚¨æ— éœ€å¯¹æ¨¡å‹æƒé‡ç­‰ç›¸å…³æ–‡ä»¶åšå‡ºä»»ä½•æ”¹åŠ¨,å¹¶å¯ä»¥ç›´æ¥æŠŠéƒ¨ç½²åŸä»“åº“çš„ä¸€åˆ‡æ­¥éª¤åº”ç”¨åˆ°æœ¬ä»“åº“ä¸Šã€‚

ç”Ÿæˆè´¨é‡å¯èƒ½æœ‰å°‘é‡ä¸‹æ»‘ã€‚




## ğŸ§° Models

|Model|Resolution|GPU Mem. & Inference Time (RTX2080Ti(22GiB), ddim 50steps)|Checkpoint|
|:---------|:---------|:--------|:--------|
|ToonCrafter_512|320x512| ~20G & 62s (`perframe_ae=True`)|[Hugging Face](https://huggingface.co/Doubiiu/ToonCrafter/blob/main/model.ckpt)|



## âš™ï¸ Setup

### Install Environment via Anaconda (Recommended)
```bash
conda create -n tooncrafter python=3.8.5
conda activate tooncrafter
pip install -r requirements.txt
```


## ğŸ’« Inference
### 1. Command line
First, create directory
```bash
mkdir checkpoints/tooncrafter_512_interp_v1
```

Then download pretrained ToonCrafter_512 and put the `model.ckpt` in `checkpoints/tooncrafter_512_interp_v1/model.ckpt`.
```bash
  sh scripts/run.sh
```


### 2. Local Gradio demo

Download the pretrained model and put it in the corresponding directory according to the previous guidelines.
```bash
  python gradio_app.py 
```




