## Introduction
This repository modifies the inference code of the Tooncrafter project to reduce GPU memory usage. You do not need to make any changes to the model itself.

Generated quality may be slightly affected.

æœ¬ä»“åº“å¯¹Tooncrafteré¡¹ç›®çš„æ¨ç†ä»£ç è¿›è¡Œä¿®æ”¹ä»¥è¾¾åˆ°å‡å°‘æ˜¾å­˜å ç”¨çš„ç›®çš„ï¼Œæ‚¨æ— éœ€å¯¹æ¨¡å‹æƒé‡ç­‰ç›¸å…³æ–‡ä»¶åšå‡ºä»»ä½•æ”¹åŠ¨ã€‚
ç”Ÿæˆè´¨é‡å¯èƒ½å—åˆ°äº›è®¸å½±å“ã€‚




## ğŸ§° Models

|Model|Resolution|GPU Mem. & Inference Time (RTX2080Ti(22GiB), ddim 50steps)|Checkpoint|
|:---------|:---------|:--------|:--------|
|ToonCrafter_512|320x512| ~24G & 24s (`perframe_ae=True`)|[Hugging Face](https://huggingface.co/Doubiiu/ToonCrafter/blob/main/model.ckpt)|



## âš™ï¸ Setup

### Install Environment via Anaconda (Recommended)
```bash
conda create -n tooncrafter python=3.8.5
conda activate tooncrafter
pip install -r requirements.txt
```


## ğŸ’« Inference
### 1. Command line
First, create directory
```bash
mkdir checkpoints/tooncrafter_512_interp_v1
```

Then download pretrained ToonCrafter_512 and put the `model.ckpt` in `checkpoints/tooncrafter_512_interp_v1/model.ckpt`.
```bash
  sh scripts/run.sh
```


### 2. Local Gradio demo

Download the pretrained model and put it in the corresponding directory according to the previous guidelines.
```bash
  python gradio_app.py 
```




